{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在MNIST数据处理中加入注意力层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import Input, Dense, Multiply\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "((x_train, y_train), (x_test, y_test)) = mnist.load_data()\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.数据变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000,784)\n",
    "x_test = x_test.reshape(10000,784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0\n",
    "\n",
    "y_train = to_categorical(y_train,10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 784)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 784)          615440      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 784)          0           input_1[0][0]                    \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           50240       multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           650         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 666,330\n",
      "Trainable params: 666,330\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#输入层\n",
    "inputs=Input(shape=(784,))\n",
    "#w\n",
    "probs=Dense(784,activation='softmax')(inputs)\n",
    "mul=Multiply()([inputs,probs])\n",
    "#fc层\n",
    "mul=Dense(64)(mul)\n",
    "#fc层\n",
    "output=Dense(10,activation='relu')(mul)\n",
    "model=Model(inputs=[inputs],outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.编译、训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1534 - accuracy: 0.7251\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1026 - accuracy: 0.8493\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0854 - accuracy: 0.8803\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0787 - accuracy: 0.9115\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0822 - accuracy: 0.9050\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0726 - accuracy: 0.9152\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0714 - accuracy: 0.9172\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0710 - accuracy: 0.9231 0s - loss: 0\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0601 - accuracy: 0.9347\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0640 - accuracy: 0.9293\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0573 - accuracy: 0.9387\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0588 - accuracy: 0.9381 0s - loss: 0.0592 - ac - ETA: 0s - loss: 0.0591 -  - ETA: 0s - loss: 0.0588 - accuracy: 0.93\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0641 - accuracy: 0.93470s - l\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0514 - accuracy: 0.9436\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0479 - accuracy: 0.9472\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0459 - accuracy: 0.9502\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0462 - accuracy: 0.9490\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0562 - accuracy: 0.9396\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0526 - accuracy: 0.9419\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0424 - accuracy: 0.9541\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0418 - accuracy: 0.9545\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0467 - accuracy: 0.9500\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0443 - accuracy: 0.9540\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0408 - accuracy: 0.9574\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0503 - accuracy: 0.9529\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0431 - accuracy: 0.9542\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0400 - accuracy: 0.9572\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0405 - accuracy: 0.9607\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0418 - accuracy: 0.9584\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0407 - accuracy: 0.9586\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0383 - accuracy: 0.9593\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.0396 - accuracy: 0.9582\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0360 - accuracy: 0.9627\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0320 - accuracy: 0.9659\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0419 - accuracy: 0.9608\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0343 - accuracy: 0.9650\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0326 - accuracy: 0.9661\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0309 - accuracy: 0.9679\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0324 - accuracy: 0.9664\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0355 - accuracy: 0.9653\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0336 - accuracy: 0.9669\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0308 - accuracy: 0.9689 0s - loss: 0.0309 - accuracy: 0.\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0320 - accuracy: 0.9679\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0319 - accuracy: 0.9686\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0313 - accuracy: 0.9702\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0306 - accuracy: 0.9700\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0302 - accuracy: 0.9706\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0276 - accuracy: 0.9732\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0279 - accuracy: 0.9729\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0313 - accuracy: 0.9706\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0292 - accuracy: 0.9723\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0282 - accuracy: 0.9723\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0340 - accuracy: 0.9711\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0286 - accuracy: 0.9732\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0271 - accuracy: 0.9743\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0279 - accuracy: 0.9739\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0265 - accuracy: 0.9737\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0280 - accuracy: 0.9736\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0319 - accuracy: 0.9720\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0299 - accuracy: 0.9725\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0274 - accuracy: 0.9743\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0262 - accuracy: 0.9747\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0287 - accuracy: 0.9732\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0249 - accuracy: 0.9766\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0228 - accuracy: 0.9779\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0246 - accuracy: 0.9772\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0258 - accuracy: 0.9768\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0249 - accuracy: 0.9778\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0279 - accuracy: 0.9757\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0278 - accuracy: 0.9769\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0311 - accuracy: 0.9731\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0390 - accuracy: 0.9693\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0279 - accuracy: 0.9752\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0299 - accuracy: 0.9741\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0245 - accuracy: 0.9776\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0246 - accuracy: 0.9786\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0249 - accuracy: 0.9784\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0266 - accuracy: 0.9776\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0277 - accuracy: 0.9767\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0253 - accuracy: 0.9778\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0259 - accuracy: 0.9781\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0242 - accuracy: 0.9788\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0259 - accuracy: 0.9760\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0287 - accuracy: 0.9754\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0248 - accuracy: 0.9753\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0214 - accuracy: 0.9808\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0232 - accuracy: 0.9801\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0266 - accuracy: 0.9783\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0229 - accuracy: 0.9794\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0249 - accuracy: 0.9780\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0201 - accuracy: 0.9816\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0299 - accuracy: 0.9746\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0231 - accuracy: 0.9799\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0213 - accuracy: 0.9815\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0233 - accuracy: 0.9800\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0265 - accuracy: 0.9770\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0230 - accuracy: 0.9810\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0221 - accuracy: 0.9812\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0284 - accuracy: 0.9779\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0308 - accuracy: 0.9766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x253d0371cc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step - loss: 0.1001 - accuracy: 0.9501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1000538244843483, 0.9501000046730042]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用自注意力机制处理IMDB影评数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences \n",
    "from keras.layers import Embedding ,Dense,Input,LSTM,Permute,Softmax,Lambda,Flatten, GRU\n",
    "from keras import Model\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.加载并格式化数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 164s 9us/step\n",
      "17473536/17464789 [==============================] - 164s 9us/step\n"
     ]
    }
   ],
   "source": [
    "max_len=200\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data()\n",
    "train_data_pad = pad_sequences(train_data,padding=\"post\",maxlen = max_len )\n",
    "test_data_pad = pad_sequences(test_data,padding=\"post\",maxlen = max_len )\n",
    "train_labels_input = to_categorical(train_labels)\n",
    "test_labels_input = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_=Input(shape=(max_len,))\n",
    "words=Embedding(100000,64)(input_)\n",
    "sen=GRU(64,return_sequences=True)(words)\n",
    "\n",
    "#注意力层\n",
    "attention_pre=Dense(64,name='attention_vec')(sen)\n",
    "attention_probs=Softmax()(attention_pre)\n",
    "attention_mul=Lambda(lambda x:x[0]*x[1])([attention_probs,sen])\n",
    "\n",
    "output=Flatten()(attention_mul)\n",
    "output=Dense(32,activation=\"relu\")(output)\n",
    "output = Dense(2, activation='softmax')(output)\n",
    "model=Model(inputs=input_,outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 200, 64)      6400000     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 200, 64)      24960       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Dense)           (None, 200, 64)      4160        gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "softmax_1 (Softmax)             (None, 200, 64)      0           attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 200, 64)      0           softmax_1[0][0]                  \n",
      "                                                                 gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 12800)        0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           409632      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            66          dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6,838,818\n",
      "Trainable params: 6,838,818\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"acc\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 131s 330ms/step - loss: 0.4241 - acc: 0.7820 - val_loss: 0.2995 - val_acc: 0.8751\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 106s 270ms/step - loss: 0.1692 - acc: 0.9375 - val_loss: 0.3254 - val_acc: 0.8667\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 147s 377ms/step - loss: 0.0759 - acc: 0.9754 - val_loss: 0.4480 - val_acc: 0.8541\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 102s 261ms/step - loss: 0.0351 - acc: 0.9888 - val_loss: 0.5426 - val_acc: 0.8452\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 86s 220ms/step - loss: 0.0188 - acc: 0.9944 - val_loss: 0.7006 - val_acc: 0.8509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x253da667da0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data_pad,train_labels_input,batch_size=64,epochs=5,\n",
    "          validation_data=(test_data_pad,test_labels_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 35s - loss: 0.7006 - acc: 0.8509\n",
      "\n",
      "Test accuracy: 0.8509200215339661\n",
      "\n",
      "Test loss: 0.7006161212921143\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data_pad,test_labels_input,verbose=2) #损失值和准确率\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "print('\\nTest loss:', test_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
