{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "655f7aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf1\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713e9660",
   "metadata": {},
   "source": [
    "### 1）生成张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8c3d202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]])>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros([3, 4], tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4538e1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1]])>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones([3, 5], tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6139d0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 6), dtype=int32, numpy=\n",
       "array([[1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1]])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.eye(6,dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "512cc2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[6, 6, 6],\n",
       "       [6, 6, 6],\n",
       "       [6, 6, 6]])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.fill([3,3],6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4c0154a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[-1.8345212 , -1.2473832 , -0.01549946, -0.16367036],\n",
       "       [ 2.1303735 , -0.66512847,  1.5054108 , -1.3861955 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal([2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d79f98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[ 1.468852  , -0.6286899 , -0.16098958, -1.144105  ],\n",
       "       [-0.24096355, -0.16640003, -0.737144  , -0.18835442]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.truncated_normal([2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d0575de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[0.99504066, 0.72150147, 0.3785714 , 0.36296248],\n",
       "       [0.24003506, 0.202268  , 0.9825257 , 0.72039783]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.uniform([2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19ff535a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([1, 8, 6, 2, 5, 7, 0, 4, 9, 3])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#随机地将张量沿其第一维度打乱\n",
    "tf.random.shuffle(tf.range(10)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6010a3",
   "metadata": {},
   "source": [
    "### 2）数据类型转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f487b2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n1: tf.Tensor(123.6, shape=(), dtype=float32)\n",
      "n2: tf.Tensor([6.9000001  1.20000005 3.5       ], shape=(3,), dtype=float64)\n",
      "n3: tf.Tensor([6.9 1.2 3.5], shape=(3,), dtype=float32)\n",
      "n4: tf.Tensor([6 1 3], shape=(3,), dtype=int32)\n",
      "n5: tf.Tensor([6 1 3], shape=(3,), dtype=int64)\n",
      "------------------------------\n",
      "n6: tf.Tensor([6.9000001  1.20000005 3.5       ], shape=(3,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "string='123.6'\n",
    "n1=tf1.string_to_number(string)\n",
    "print('n1:',n1)\n",
    "a=[6.9,1.2,3.5]\n",
    "n2=tf1.cast(a,tf.double)\n",
    "print('n2:',n2)\n",
    "\n",
    "n3=tf1.cast(a,tf.float32)\n",
    "print('n3:',n3)\n",
    "\n",
    "n4=tf1.cast(a,tf.int32)\n",
    "print('n4:',n4)\n",
    "\n",
    "n5=tf1.cast(a,tf.int64)\n",
    "print('n5:',n5)\n",
    "\n",
    "print('-'*30)\n",
    "n6=tf1.to_double(a)\n",
    "print('n6:',n6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f11018",
   "metadata": {},
   "source": [
    "### 3) 形状操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15f0633",
   "metadata": {},
   "source": [
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c951f793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 2, 3])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]\n",
    "tf.shape(t) #返回数据的shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9666e88c",
   "metadata": {},
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20338ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=12>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]\n",
    "tf.size(t) #返回数据的元素数量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d460b60",
   "metadata": {},
   "source": [
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61c8b900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]\n",
    "tf.rank(t) #维度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61da9c03",
   "metadata": {},
   "source": [
    "reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c89d661c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([9], shape=(1,), dtype=int32)\n",
      "tf.Tensor([3 3], shape=(2,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "t = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "print(tf.shape(t))\n",
    "\n",
    "t2 = tf.reshape(t, [3, 3])\n",
    "print(tf.shape(t2))\n",
    "\n",
    "t3 = tf.reshape(t, [3, -1])\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba19f9d",
   "metadata": {},
   "source": [
    "### 4）Tensor切片操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9b0834",
   "metadata": {},
   "source": [
    "expand_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7360c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([3])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [4,3,2]\n",
    "tf.shape(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeefca91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 3], shape=(2,), dtype=int32) \n",
      " tf.Tensor([3 1], shape=(2,), dtype=int32) \n",
      " tf.Tensor([3 1], shape=(2,), dtype=int32)\n",
      "------------------------------\n",
      "tf.Tensor(\n",
      "[[[1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]]], shape=(2, 3, 5), dtype=float32)\n",
      "tf.Tensor([1 2 3 5], shape=(4,), dtype=int32) \n",
      " tf.Tensor([2 3 1 5], shape=(4,), dtype=int32) \n",
      " tf.Tensor([2 3 5 1], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "t = [4,3,2]\n",
    "t1 = tf.shape(tf.expand_dims(t, 0))\n",
    "t2 = tf.shape(tf.expand_dims(t, 1))\n",
    "t3 = tf.shape(tf.expand_dims(t, -1))\n",
    "print(t1,'\\n',t2,'\\n',t3)\n",
    "print('-'*30)\n",
    "t4 = tf.ones([2,3,5])\n",
    "t5 = tf.shape(tf.expand_dims(t4, 0))\n",
    "t6 = tf.shape(tf.expand_dims(t4, 2))\n",
    "t7 = tf.shape(tf.expand_dims(t4, -1))\n",
    "print(t4)\n",
    "print(t5,'\\n',t6,'\\n',t7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa6643b",
   "metadata": {},
   "source": [
    "slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5736353d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[3 3 3]]], shape=(1, 1, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "t = [[[1, 1, 1], [2, 2, 2]],[[3, 3, 3], [4, 4, 4]],[[5, 5, 5], [6, 6, 6]]]\n",
    "t1 = tf.slice(t, [1, 0, 0], [1, 1, 3])\n",
    "t2 = tf.slice(t, [1, 0, 0], [1, 2, 3])\n",
    "t3 = tf.slice(t, [1, 0, 0], [2, 1, 3])\n",
    "\n",
    "print(t1)\n",
    "# print(t2)\n",
    "# print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07eb9c6",
   "metadata": {},
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "309ff08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 5 10], shape=(2,), dtype=int32)\n",
      "tf.Tensor([ 5 10], shape=(2,), dtype=int32)\n",
      "tf.Tensor([ 5 10], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "s=tf.fill([5,30],9)\n",
    "s0,s1,s2=tf.split(s,3,1)\n",
    "print(tf.shape(s0))\n",
    "print(tf.shape(s1))\n",
    "print(tf.shape(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc97910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      " [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      " [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      " [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      " [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]], shape=(5, 30), dtype=int32)\n",
      "tf.Tensor([ 5 10], shape=(2,), dtype=int32)\n",
      "tf.Tensor([ 5 10], shape=(2,), dtype=int32)\n",
      "tf.Tensor([ 5 10], shape=(2,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[9 9 9 9 9 9 9 9 9 9]\n",
      " [9 9 9 9 9 9 9 9 9 9]\n",
      " [9 9 9 9 9 9 9 9 9 9]\n",
      " [9 9 9 9 9 9 9 9 9 9]\n",
      " [9 9 9 9 9 9 9 9 9 9]], shape=(5, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "s=tf.fill([5,30],9)\n",
    "print(s)\n",
    "s0,s1,s2=tf.split(s,num_or_size_splits=3,axis=1)\n",
    "print(tf.shape(s0))\n",
    "print(tf.shape(s1))\n",
    "print(tf.shape(s2))\n",
    "print(s0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e63397",
   "metadata": {},
   "source": [
    "concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba5c553d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]], shape=(4, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 1  2  3  7  8  9]\n",
      " [ 4  5  6 10 11 12]], shape=(2, 6), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "t1 = [[1, 2, 3], [4, 5, 6]]\n",
    "t2 = [[7, 8, 9], [10, 11, 12]]\n",
    "t3 = tf.concat([t1, t2], 0) \n",
    "t4 = tf.concat([t1, t2], 1) \n",
    "print(t3)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9c4a4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]], shape=(4, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "t1 = [[1, 2, 3], [4, 5, 6]]\n",
    "t2 = [[7, 8, 9], [10, 11, 12]]\n",
    "t3 = tf.concat([t1, t2], 0)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca346efd",
   "metadata": {},
   "source": [
    "stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82f14439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]], shape=(3, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = [1, 4]\n",
    "y = [2, 5]\n",
    "z = [3, 6]\n",
    "t1 =tf.stack([x, y, z])\n",
    "print(t1)\n",
    "#沿着第一维stack\n",
    "t2 = tf.stack([x, y, z], axis=1)\n",
    "print(t2)\n",
    "\n",
    "#等价于\n",
    "# t3 = np.asarray([x, y, z])\n",
    "# print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ac270f",
   "metadata": {},
   "source": [
    "reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3fc932f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 3  2  1  0]\n",
      "   [ 7  6  5  4]\n",
      "   [11 10  9  8]]\n",
      "\n",
      "  [[15 14 13 12]\n",
      "   [19 18 17 16]\n",
      "   [23 22 21 20]]]], shape=(1, 2, 3, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[[ 3  2  1  0]\n",
      "   [ 7  6  5  4]\n",
      "   [11 10  9  8]]\n",
      "\n",
      "  [[15 14 13 12]\n",
      "   [19 18 17 16]\n",
      "   [23 22 21 20]]]], shape=(1, 2, 3, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[[12 13 14 15]\n",
      "   [16 17 18 19]\n",
      "   [20 21 22 23]]\n",
      "\n",
      "  [[ 0  1  2  3]\n",
      "   [ 4  5  6  7]\n",
      "   [ 8  9 10 11]]]], shape=(1, 2, 3, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[[ 8  9 10 11]\n",
      "   [ 4  5  6  7]\n",
      "   [ 0  1  2  3]]\n",
      "\n",
      "  [[20 21 22 23]\n",
      "   [16 17 18 19]\n",
      "   [12 13 14 15]]]], shape=(1, 2, 3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "t = [[[[ 0,  1,  2,  3],\n",
    "[ 4,  5,  6,  7],\n",
    "[ 8,  9, 10, 11]],\n",
    "[[12, 13, 14, 15],\n",
    "[16, 17, 18, 19],\n",
    "[20, 21, 22, 23]]]]\n",
    "# tensor 't' shape is [1, 2, 3, 4]\n",
    "\n",
    "dims = [3]  # or 'dims = [-1]''\n",
    "t1 = tf.reverse(t, dims)\n",
    "print(t1)\n",
    "\n",
    "dims = [1] #or 'dims = [-3]'\n",
    "t2 = tf.reverse(t, dims)\n",
    "\n",
    "dims = [2] #or 'dims = [-2]'\n",
    "t3 = tf.reverse(t, dims)\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566ed6e5",
   "metadata": {},
   "source": [
    "transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfdd7e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]], shape=(3, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]], shape=(3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "t = [[1, 2, 3],[4, 5, 6]]\n",
    "t1 = tf.transpose(t) \n",
    "t2 = tf.transpose(t, perm=[1, 0])\n",
    "print(t1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dabdf38",
   "metadata": {},
   "source": [
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40b21895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]], shape=(3, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[5. 0. 0.]\n",
      " [0. 0. 5.]\n",
      " [0. 0. 0.]\n",
      " [0. 5. 0.]], shape=(4, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[1. 0. 0.]\n",
      "  [0. 0. 1.]]\n",
      "\n",
      " [[0. 1. 0.]\n",
      "  [0. 0. 0.]]], shape=(2, 2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "indices = [0, 1, 2]\n",
    "depth = 3\n",
    "t1 = tf.one_hot(indices, depth)  \n",
    "\n",
    "indices = [0, 2, -1, 1]\n",
    "depth = 3\n",
    "t2 = tf.one_hot(indices, depth,on_value=5.0, off_value=0.0,axis=-1)  \n",
    "indices = [[0, 2], [1, -1]]\n",
    "t3 = tf.one_hot(indices, depth,on_value=1.0, off_value=0.0,axis=-1)  \n",
    "\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e962abc7",
   "metadata": {},
   "source": [
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95c9fc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 4 7 8], shape=(5,), dtype=int32)\n",
      "tf.Tensor([0 0 1 2 2 2 3 4 4], shape=(9,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "t = [1, 1, 2, 4, 4, 4, 7, 8, 8]\n",
    "y, idx = tf.unique(t)\n",
    "print(y)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba60dbc3",
   "metadata": {},
   "source": [
    "### 5）矩阵操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f0dc08",
   "metadata": {},
   "source": [
    "matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cee720e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
    "b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n",
    "c = tf.matmul(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3103f643",
   "metadata": {},
   "source": [
    "diag对角矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7020a6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=int32, numpy=\n",
       "array([[1, 0, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [0, 0, 3, 0],\n",
       "       [0, 0, 0, 4]])>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagonal = [1, 2, 3, 4]\n",
    "tf.linalg.diag(diagonal) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e242e25",
   "metadata": {},
   "source": [
    "det求方阵行列式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67f2db7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-2.0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# 定义一个2x2的矩阵\n",
    "matrix = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "\n",
    "# 计算矩阵的行列式\n",
    "tf.linalg.det(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5bf66037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[-2.0000002 ,  1.0000001 ],\n",
       "       [ 1.5000001 , -0.50000006]], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.linalg.inv(x)的例子\n",
    "matrix = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "tf.linalg.inv(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "faebbbe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=5.0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.linalg.trace(x)的例子\n",
    "matrix = tf.constant([[1.0, 3.0], [3.0, 4.0]])\n",
    "tf.linalg.trace(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91facf63",
   "metadata": {},
   "source": [
    "### 6) 复数操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4144ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=complex64, numpy=array([1.1+3.3j, 2.2+4.4j], dtype=complex64)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real=[1.1, 2.2]\n",
    "imag=[3.3, 4.4]\n",
    "tf.complex(real, imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb480ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([3.4785054, 4.9193497], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=tf.complex(real, imag)\n",
    "tf.abs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "290c6cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=complex64, numpy=array([1.1-3.3j, 2.2-4.4j], dtype=complex64)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.conj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bd90e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([3.3, 4.4], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.imag(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6bbdf5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.1, 2.2], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.real(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c06db82",
   "metadata": {},
   "source": [
    "### 练习1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da018237",
   "metadata": {},
   "source": [
    "#### 1）读取数据并查看数据结构 下载pima-indians-diabetes.csv文件并在python中加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec5401dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.639947</td>\n",
       "      <td>0.866045</td>\n",
       "      <td>-0.031990</td>\n",
       "      <td>0.670643</td>\n",
       "      <td>-0.181541</td>\n",
       "      <td>0.166619</td>\n",
       "      <td>0.468492</td>\n",
       "      <td>1.425995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-1.205066</td>\n",
       "      <td>-0.528319</td>\n",
       "      <td>-0.012301</td>\n",
       "      <td>-0.181541</td>\n",
       "      <td>-0.852200</td>\n",
       "      <td>-0.365061</td>\n",
       "      <td>-0.190672</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.233880</td>\n",
       "      <td>2.016662</td>\n",
       "      <td>-0.693761</td>\n",
       "      <td>-0.012301</td>\n",
       "      <td>-0.181541</td>\n",
       "      <td>-1.332500</td>\n",
       "      <td>0.604397</td>\n",
       "      <td>-0.105584</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-1.073567</td>\n",
       "      <td>-0.528319</td>\n",
       "      <td>-0.695245</td>\n",
       "      <td>-0.540642</td>\n",
       "      <td>-0.633881</td>\n",
       "      <td>-0.920763</td>\n",
       "      <td>-1.041549</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.141852</td>\n",
       "      <td>0.504422</td>\n",
       "      <td>-2.679076</td>\n",
       "      <td>0.670643</td>\n",
       "      <td>0.316566</td>\n",
       "      <td>1.549303</td>\n",
       "      <td>5.484909</td>\n",
       "      <td>-0.020496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>1.827813</td>\n",
       "      <td>-0.679069</td>\n",
       "      <td>0.298896</td>\n",
       "      <td>2.150354</td>\n",
       "      <td>0.455573</td>\n",
       "      <td>0.064737</td>\n",
       "      <td>-0.908682</td>\n",
       "      <td>2.532136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>-0.547919</td>\n",
       "      <td>0.011301</td>\n",
       "      <td>-0.197433</td>\n",
       "      <td>-0.239949</td>\n",
       "      <td>-0.181541</td>\n",
       "      <td>0.632365</td>\n",
       "      <td>-0.398282</td>\n",
       "      <td>-0.531023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.342981</td>\n",
       "      <td>-0.021574</td>\n",
       "      <td>-0.031990</td>\n",
       "      <td>-0.695245</td>\n",
       "      <td>-0.332132</td>\n",
       "      <td>-0.910418</td>\n",
       "      <td>-0.685193</td>\n",
       "      <td>-0.275760</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>0.142800</td>\n",
       "      <td>-1.024647</td>\n",
       "      <td>-0.012301</td>\n",
       "      <td>-0.181541</td>\n",
       "      <td>-0.342790</td>\n",
       "      <td>-0.371101</td>\n",
       "      <td>1.170732</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-0.942068</td>\n",
       "      <td>-0.197433</td>\n",
       "      <td>0.215347</td>\n",
       "      <td>-0.181541</td>\n",
       "      <td>-0.299127</td>\n",
       "      <td>-0.473785</td>\n",
       "      <td>-0.871374</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.639947  0.866045 -0.031990  0.670643 -0.181541  0.166619  0.468492   \n",
       "1   -0.844885 -1.205066 -0.528319 -0.012301 -0.181541 -0.852200 -0.365061   \n",
       "2    1.233880  2.016662 -0.693761 -0.012301 -0.181541 -1.332500  0.604397   \n",
       "3   -0.844885 -1.073567 -0.528319 -0.695245 -0.540642 -0.633881 -0.920763   \n",
       "4   -1.141852  0.504422 -2.679076  0.670643  0.316566  1.549303  5.484909   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "763  1.827813 -0.679069  0.298896  2.150354  0.455573  0.064737 -0.908682   \n",
       "764 -0.547919  0.011301 -0.197433 -0.239949 -0.181541  0.632365 -0.398282   \n",
       "765  0.342981 -0.021574 -0.031990 -0.695245 -0.332132 -0.910418 -0.685193   \n",
       "766 -0.844885  0.142800 -1.024647 -0.012301 -0.181541 -0.342790 -0.371101   \n",
       "767 -0.844885 -0.942068 -0.197433  0.215347 -0.181541 -0.299127 -0.473785   \n",
       "\n",
       "            7  8  \n",
       "0    1.425995  1  \n",
       "1   -0.190672  0  \n",
       "2   -0.105584  1  \n",
       "3   -1.041549  0  \n",
       "4   -0.020496  1  \n",
       "..        ... ..  \n",
       "763  2.532136  0  \n",
       "764 -0.531023  0  \n",
       "765 -0.275760  0  \n",
       "766  1.170732  1  \n",
       "767 -0.871374  0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 加载数据\n",
    "data = pd.read_csv(\"pima-indians-diabetes.csv\",header=None,delimiter=\",\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00bb514c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.639947</td>\n",
       "      <td>0.866045</td>\n",
       "      <td>-0.031990</td>\n",
       "      <td>0.670643</td>\n",
       "      <td>-0.181541</td>\n",
       "      <td>0.166619</td>\n",
       "      <td>0.468492</td>\n",
       "      <td>1.425995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-1.205066</td>\n",
       "      <td>-0.528319</td>\n",
       "      <td>-0.012301</td>\n",
       "      <td>-0.181541</td>\n",
       "      <td>-0.852200</td>\n",
       "      <td>-0.365061</td>\n",
       "      <td>-0.190672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.233880</td>\n",
       "      <td>2.016662</td>\n",
       "      <td>-0.693761</td>\n",
       "      <td>-0.012301</td>\n",
       "      <td>-0.181541</td>\n",
       "      <td>-1.332500</td>\n",
       "      <td>0.604397</td>\n",
       "      <td>-0.105584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-1.073567</td>\n",
       "      <td>-0.528319</td>\n",
       "      <td>-0.695245</td>\n",
       "      <td>-0.540642</td>\n",
       "      <td>-0.633881</td>\n",
       "      <td>-0.920763</td>\n",
       "      <td>-1.041549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.141852</td>\n",
       "      <td>0.504422</td>\n",
       "      <td>-2.679076</td>\n",
       "      <td>0.670643</td>\n",
       "      <td>0.316566</td>\n",
       "      <td>1.549303</td>\n",
       "      <td>5.484909</td>\n",
       "      <td>-0.020496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>1.827813</td>\n",
       "      <td>-0.679069</td>\n",
       "      <td>0.298896</td>\n",
       "      <td>2.150354</td>\n",
       "      <td>0.455573</td>\n",
       "      <td>0.064737</td>\n",
       "      <td>-0.908682</td>\n",
       "      <td>2.532136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>-0.547919</td>\n",
       "      <td>0.011301</td>\n",
       "      <td>-0.197433</td>\n",
       "      <td>-0.239949</td>\n",
       "      <td>-0.181541</td>\n",
       "      <td>0.632365</td>\n",
       "      <td>-0.398282</td>\n",
       "      <td>-0.531023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.342981</td>\n",
       "      <td>-0.021574</td>\n",
       "      <td>-0.031990</td>\n",
       "      <td>-0.695245</td>\n",
       "      <td>-0.332132</td>\n",
       "      <td>-0.910418</td>\n",
       "      <td>-0.685193</td>\n",
       "      <td>-0.275760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>0.142800</td>\n",
       "      <td>-1.024647</td>\n",
       "      <td>-0.012301</td>\n",
       "      <td>-0.181541</td>\n",
       "      <td>-0.342790</td>\n",
       "      <td>-0.371101</td>\n",
       "      <td>1.170732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-0.942068</td>\n",
       "      <td>-0.197433</td>\n",
       "      <td>0.215347</td>\n",
       "      <td>-0.181541</td>\n",
       "      <td>-0.299127</td>\n",
       "      <td>-0.473785</td>\n",
       "      <td>-0.871374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.639947  0.866045 -0.031990  0.670643 -0.181541  0.166619  0.468492   \n",
       "1   -0.844885 -1.205066 -0.528319 -0.012301 -0.181541 -0.852200 -0.365061   \n",
       "2    1.233880  2.016662 -0.693761 -0.012301 -0.181541 -1.332500  0.604397   \n",
       "3   -0.844885 -1.073567 -0.528319 -0.695245 -0.540642 -0.633881 -0.920763   \n",
       "4   -1.141852  0.504422 -2.679076  0.670643  0.316566  1.549303  5.484909   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "763  1.827813 -0.679069  0.298896  2.150354  0.455573  0.064737 -0.908682   \n",
       "764 -0.547919  0.011301 -0.197433 -0.239949 -0.181541  0.632365 -0.398282   \n",
       "765  0.342981 -0.021574 -0.031990 -0.695245 -0.332132 -0.910418 -0.685193   \n",
       "766 -0.844885  0.142800 -1.024647 -0.012301 -0.181541 -0.342790 -0.371101   \n",
       "767 -0.844885 -0.942068 -0.197433  0.215347 -0.181541 -0.299127 -0.473785   \n",
       "\n",
       "            7  \n",
       "0    1.425995  \n",
       "1   -0.190672  \n",
       "2   -0.105584  \n",
       "3   -1.041549  \n",
       "4   -0.020496  \n",
       "..        ...  \n",
       "763  2.532136  \n",
       "764 -0.531023  \n",
       "765 -0.275760  \n",
       "766  1.170732  \n",
       "767 -0.871374  \n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=data.iloc[:,0:8]\n",
    "y=data[8]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c328c0",
   "metadata": {},
   "source": [
    "### 2）设计神经网络并训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a06410ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten,Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6c92cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "77/77 [==============================] - 0s 471us/step - loss: 0.7714 - accuracy: 0.4232\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 0s 445us/step - loss: 0.6274 - accuracy: 0.6615\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 0s 392us/step - loss: 0.5522 - accuracy: 0.7344\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 0s 389us/step - loss: 0.5127 - accuracy: 0.7474\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 0s 303us/step - loss: 0.4903 - accuracy: 0.7448\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 0s 258us/step - loss: 0.4763 - accuracy: 0.7539\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 0s 394us/step - loss: 0.4677 - accuracy: 0.7591\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 0s 300us/step - loss: 0.4615 - accuracy: 0.7656\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 0s 395us/step - loss: 0.4568 - accuracy: 0.7682\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 0s 408us/step - loss: 0.4533 - accuracy: 0.7721\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 0s 407us/step - loss: 0.4509 - accuracy: 0.7747\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 0s 422us/step - loss: 0.4488 - accuracy: 0.7747\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 0s 288us/step - loss: 0.4472 - accuracy: 0.7747\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 0s 396us/step - loss: 0.4456 - accuracy: 0.7773\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 0s 396us/step - loss: 0.4441 - accuracy: 0.7786\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 0s 394us/step - loss: 0.4431 - accuracy: 0.7799\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 0s 446us/step - loss: 0.4420 - accuracy: 0.7760\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 0s 407us/step - loss: 0.4412 - accuracy: 0.7786\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 0s 356us/step - loss: 0.4404 - accuracy: 0.7786\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 0s 394us/step - loss: 0.4394 - accuracy: 0.7773\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 0s 347us/step - loss: 0.4389 - accuracy: 0.7826\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 0s 416us/step - loss: 0.4380 - accuracy: 0.7812\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 0s 261us/step - loss: 0.4370 - accuracy: 0.7799\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 0s 393us/step - loss: 0.4366 - accuracy: 0.7786\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 0s 391us/step - loss: 0.4359 - accuracy: 0.7786\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 0s 462us/step - loss: 0.4354 - accuracy: 0.7812\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 0s 395us/step - loss: 0.4347 - accuracy: 0.7786\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 0s 295us/step - loss: 0.4342 - accuracy: 0.7786\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 0s 395us/step - loss: 0.4334 - accuracy: 0.7826\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 0s 395us/step - loss: 0.4330 - accuracy: 0.7799\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 0s 667us/step - loss: 0.4321 - accuracy: 0.7826\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 0s 419us/step - loss: 0.4317 - accuracy: 0.7812\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 0s 438us/step - loss: 0.4315 - accuracy: 0.7852\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 0s 355us/step - loss: 0.4310 - accuracy: 0.7839\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 0s 328us/step - loss: 0.4306 - accuracy: 0.7799\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 0s 395us/step - loss: 0.4299 - accuracy: 0.7799\n",
      "Epoch 37/100\n",
      "77/77 [==============================] - 0s 581us/step - loss: 0.4293 - accuracy: 0.7812\n",
      "Epoch 38/100\n",
      "77/77 [==============================] - 0s 430us/step - loss: 0.4293 - accuracy: 0.7773\n",
      "Epoch 39/100\n",
      "77/77 [==============================] - 0s 398us/step - loss: 0.4286 - accuracy: 0.7812\n",
      "Epoch 40/100\n",
      "77/77 [==============================] - 0s 519us/step - loss: 0.4285 - accuracy: 0.7773\n",
      "Epoch 41/100\n",
      "77/77 [==============================] - 0s 465us/step - loss: 0.4281 - accuracy: 0.7760\n",
      "Epoch 42/100\n",
      "77/77 [==============================] - 0s 325us/step - loss: 0.4275 - accuracy: 0.7786\n",
      "Epoch 43/100\n",
      "77/77 [==============================] - 0s 530us/step - loss: 0.4271 - accuracy: 0.7760\n",
      "Epoch 44/100\n",
      "77/77 [==============================] - 0s 392us/step - loss: 0.4265 - accuracy: 0.7826\n",
      "Epoch 45/100\n",
      "77/77 [==============================] - 0s 330us/step - loss: 0.4267 - accuracy: 0.7747\n",
      "Epoch 46/100\n",
      "77/77 [==============================] - 0s 463us/step - loss: 0.4261 - accuracy: 0.7773\n",
      "Epoch 47/100\n",
      "77/77 [==============================] - 0s 363us/step - loss: 0.4257 - accuracy: 0.7799\n",
      "Epoch 48/100\n",
      "77/77 [==============================] - 0s 400us/step - loss: 0.4257 - accuracy: 0.7786\n",
      "Epoch 49/100\n",
      "77/77 [==============================] - 0s 340us/step - loss: 0.4252 - accuracy: 0.7760\n",
      "Epoch 50/100\n",
      "77/77 [==============================] - 0s 425us/step - loss: 0.4251 - accuracy: 0.7839\n",
      "Epoch 51/100\n",
      "77/77 [==============================] - 0s 286us/step - loss: 0.4246 - accuracy: 0.7852\n",
      "Epoch 52/100\n",
      "77/77 [==============================] - 0s 385us/step - loss: 0.4241 - accuracy: 0.7786\n",
      "Epoch 53/100\n",
      "77/77 [==============================] - 0s 351us/step - loss: 0.4239 - accuracy: 0.7799\n",
      "Epoch 54/100\n",
      "77/77 [==============================] - 0s 401us/step - loss: 0.4228 - accuracy: 0.7839\n",
      "Epoch 55/100\n",
      "77/77 [==============================] - 0s 259us/step - loss: 0.4227 - accuracy: 0.7852\n",
      "Epoch 56/100\n",
      "77/77 [==============================] - 0s 393us/step - loss: 0.4219 - accuracy: 0.7826\n",
      "Epoch 57/100\n",
      "77/77 [==============================] - 0s 476us/step - loss: 0.4215 - accuracy: 0.7812\n",
      "Epoch 58/100\n",
      "77/77 [==============================] - 0s 368us/step - loss: 0.4211 - accuracy: 0.7904\n",
      "Epoch 59/100\n",
      "77/77 [==============================] - 0s 315us/step - loss: 0.4204 - accuracy: 0.7839\n",
      "Epoch 60/100\n",
      "77/77 [==============================] - 0s 350us/step - loss: 0.4202 - accuracy: 0.7865\n",
      "Epoch 61/100\n",
      "77/77 [==============================] - 0s 421us/step - loss: 0.4196 - accuracy: 0.7839\n",
      "Epoch 62/100\n",
      "77/77 [==============================] - 0s 418us/step - loss: 0.4191 - accuracy: 0.7930\n",
      "Epoch 63/100\n",
      "77/77 [==============================] - 0s 346us/step - loss: 0.4189 - accuracy: 0.7917\n",
      "Epoch 64/100\n",
      "77/77 [==============================] - 0s 394us/step - loss: 0.4182 - accuracy: 0.7917\n",
      "Epoch 65/100\n",
      "77/77 [==============================] - 0s 395us/step - loss: 0.4179 - accuracy: 0.7891\n",
      "Epoch 66/100\n",
      "77/77 [==============================] - 0s 394us/step - loss: 0.4178 - accuracy: 0.7891\n",
      "Epoch 67/100\n",
      "77/77 [==============================] - 0s 398us/step - loss: 0.4170 - accuracy: 0.7969\n",
      "Epoch 68/100\n",
      "77/77 [==============================] - 0s 519us/step - loss: 0.4166 - accuracy: 0.7891\n",
      "Epoch 69/100\n",
      "77/77 [==============================] - 0s 397us/step - loss: 0.4162 - accuracy: 0.7904\n",
      "Epoch 70/100\n",
      "77/77 [==============================] - 0s 398us/step - loss: 0.4164 - accuracy: 0.7943\n",
      "Epoch 71/100\n",
      "77/77 [==============================] - 0s 421us/step - loss: 0.4158 - accuracy: 0.7943\n",
      "Epoch 72/100\n",
      "77/77 [==============================] - 0s 418us/step - loss: 0.4153 - accuracy: 0.7956\n",
      "Epoch 73/100\n",
      "77/77 [==============================] - 0s 406us/step - loss: 0.4147 - accuracy: 0.7982\n",
      "Epoch 74/100\n",
      "77/77 [==============================] - 0s 319us/step - loss: 0.4144 - accuracy: 0.7956\n",
      "Epoch 75/100\n",
      "77/77 [==============================] - 0s 358us/step - loss: 0.4147 - accuracy: 0.7969\n",
      "Epoch 76/100\n",
      "77/77 [==============================] - 0s 376us/step - loss: 0.4140 - accuracy: 0.7982\n",
      "Epoch 77/100\n",
      "77/77 [==============================] - 0s 347us/step - loss: 0.4135 - accuracy: 0.7969\n",
      "Epoch 78/100\n",
      "77/77 [==============================] - 0s 329us/step - loss: 0.4132 - accuracy: 0.7969\n",
      "Epoch 79/100\n",
      "77/77 [==============================] - 0s 415us/step - loss: 0.4128 - accuracy: 0.8021\n",
      "Epoch 80/100\n",
      "77/77 [==============================] - 0s 347us/step - loss: 0.4126 - accuracy: 0.7982\n",
      "Epoch 81/100\n",
      "77/77 [==============================] - 0s 582us/step - loss: 0.4129 - accuracy: 0.7995\n",
      "Epoch 82/100\n",
      "77/77 [==============================] - 0s 398us/step - loss: 0.4124 - accuracy: 0.7982\n",
      "Epoch 83/100\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.8316 - accuracy: 0.60 - 0s 392us/step - loss: 0.4118 - accuracy: 0.7956\n",
      "Epoch 84/100\n",
      "77/77 [==============================] - 0s 401us/step - loss: 0.4112 - accuracy: 0.7969\n",
      "Epoch 85/100\n",
      "77/77 [==============================] - 0s 393us/step - loss: 0.4111 - accuracy: 0.7930\n",
      "Epoch 86/100\n",
      "77/77 [==============================] - 0s 397us/step - loss: 0.4104 - accuracy: 0.7969\n",
      "Epoch 87/100\n",
      "77/77 [==============================] - 0s 398us/step - loss: 0.4105 - accuracy: 0.7982\n",
      "Epoch 88/100\n",
      "77/77 [==============================] - 0s 389us/step - loss: 0.4100 - accuracy: 0.7956\n",
      "Epoch 89/100\n",
      "77/77 [==============================] - 0s 398us/step - loss: 0.4094 - accuracy: 0.8008\n",
      "Epoch 90/100\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.4305 - accuracy: 0.80 - 0s 327us/step - loss: 0.4095 - accuracy: 0.7956\n",
      "Epoch 91/100\n",
      "77/77 [==============================] - 0s 289us/step - loss: 0.4089 - accuracy: 0.7930\n",
      "Epoch 92/100\n",
      "77/77 [==============================] - 0s 391us/step - loss: 0.4085 - accuracy: 0.7982\n",
      "Epoch 93/100\n",
      "77/77 [==============================] - 0s 314us/step - loss: 0.4086 - accuracy: 0.8021\n",
      "Epoch 94/100\n",
      "77/77 [==============================] - 0s 394us/step - loss: 0.4081 - accuracy: 0.7917\n",
      "Epoch 95/100\n",
      "77/77 [==============================] - 0s 394us/step - loss: 0.4085 - accuracy: 0.7969\n",
      "Epoch 96/100\n",
      "77/77 [==============================] - 0s 402us/step - loss: 0.4077 - accuracy: 0.7982\n",
      "Epoch 97/100\n",
      "77/77 [==============================] - 0s 352us/step - loss: 0.4076 - accuracy: 0.7969\n",
      "Epoch 98/100\n",
      "77/77 [==============================] - 0s 423us/step - loss: 0.4074 - accuracy: 0.7969\n",
      "Epoch 99/100\n",
      "77/77 [==============================] - 0s 265us/step - loss: 0.4068 - accuracy: 0.7982\n",
      "Epoch 100/100\n",
      "77/77 [==============================] - 0s 399us/step - loss: 0.4073 - accuracy: 0.7930\n",
      "24/24 [==============================] - 0s 506us/step - loss: 0.4045 - accuracy: 0.7969\n",
      "\n",
      "Loss: 0.40, Accuracy: 79.69%\n",
      "Prediction Accuracy: 79.69%\n"
     ]
    }
   ],
   "source": [
    "'''模型'''\n",
    "model=Sequential([\n",
    "    Dense(12,input_dim=8,activation='relu'), #全连接\n",
    "    Dense(1, activation='sigmoid') #输出层\n",
    "])\n",
    "\n",
    "'''编译'''\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "'''训练'''\n",
    "model.fit(X,y,epochs=100,batch_size=10)\n",
    "\n",
    "'''评估'''\n",
    "loss, accuracy = model.evaluate(X, y)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "\n",
    "'''预测'''\n",
    "pred = model.predict(X)\n",
    "predictions = [float(np.round(x)) for x in pred]\n",
    "accuracy = np.mean(predictions == y)\n",
    "print(\"Prediction Accuracy: %.2f%%\" % (accuracy*100))\n",
    "# Loss: 0.40, Accuracy: 81.64%\n",
    "# Prediction Accuracy: 81.64%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ea51411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 加载数据\n",
    "# dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# X = dataset[:,0:8]\n",
    "# Y = dataset[:,8]\n",
    "\n",
    "# # step 1. define the network\n",
    "# model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.layers.Dense(12, input_dim=8, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "# # step 2. compile the network\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "#               metrics=['accuracy'])\n",
    "# # step 3. fit the network\n",
    "# history = model.fit(X, Y, epochs=100, batch_size=10)\n",
    "# # step 4. evaluate the network\n",
    "# loss, accuracy = model.evaluate(X, Y)\n",
    "# print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "# # step 5. make predictions\n",
    "# probabilities = model.predict(X)\n",
    "# predictions = [float(numpy.round(x)) for x in probabilities]\n",
    "# accuracy = numpy.mean(predictions == Y)\n",
    "# print(\"Prediction Accuracy: %.2f%%\" % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e928c1e",
   "metadata": {},
   "source": [
    "### 3）保存和加载模型 TensorFlow有两种保存模型的方法，一种是只保存模型的权重和偏置，另一种是保存整个模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924eb06f",
   "metadata": {},
   "source": [
    "（1）保存模型的权重和偏置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12017bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''保存模型的权重和偏置'''\n",
    "model.save_weights('./save_weights/my_save_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3d049c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x218d6d9eb00>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''恢复权重'''\n",
    "model.load_weights('./save_weights/my_save_weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae3c863",
   "metadata": {},
   "source": [
    "（2）保存整个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "92450be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''保存整个模型'''\n",
    "model.save('my_model.h5')\n",
    "restored_model = tf.keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73b76cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4045 - accuracy: 0.7969\n",
      "\n",
      "Loss: 0.40, Accuracy: 79.69%\n"
     ]
    }
   ],
   "source": [
    "restored_model = tf.keras.models.load_model('my_model.h5')\n",
    "loss, accuracy = restored_model.evaluate(X, y)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbc04f7",
   "metadata": {},
   "source": [
    "### 完成MNIST数据读取、模型搭建、训练、测试等过程，并尝试修改模型以提高测试效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aef5b265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2938 - accuracy: 0.9149\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1397 - accuracy: 0.9583\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1066 - accuracy: 0.9674\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0858 - accuracy: 0.9740\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0741 - accuracy: 0.9767\n",
      "313/313 - 1s - loss: 0.0707 - accuracy: 0.9769\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def load_data(path):\n",
    "    with np.load(path) as f:\n",
    "        x_train, y_train = f['x_train'], f['y_train']\n",
    "        x_test, y_test = f['x_test'], f['y_test']\n",
    "        return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "((trainX, trainY), (testX, testY)) = load_data(\"mnist.npz\")\n",
    "trainX = trainX.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(trainX, trainY, epochs=5)\n",
    "model.evaluate(testX,  testY, verbose=2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85e7348a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0791 - accuracy: 0.9759\n",
      "\n",
      "Test accuracy: 0.9758999943733215\n",
      "\n",
      "Test loss: 0.07912839949131012\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(testX,testY,verbose=2) #损失值和准确率\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "print('\\nTest loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9b49a468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1875/1875 [==============================] - 2s 979us/step - loss: 0.2905 - accuracy: 0.9157\n",
      "Epoch 2/500\n",
      "1875/1875 [==============================] - 2s 818us/step - loss: 0.1412 - accuracy: 0.9575\n",
      "Epoch 3/500\n",
      "1875/1875 [==============================] - 1s 755us/step - loss: 0.1074 - accuracy: 0.9670\n",
      "Epoch 4/500\n",
      "1875/1875 [==============================] - 1s 741us/step - loss: 0.0849 - accuracy: 0.9740\n",
      "Epoch 5/500\n",
      "1875/1875 [==============================] - 1s 734us/step - loss: 0.0731 - accuracy: 0.9775\n",
      "Epoch 6/500\n",
      "1875/1875 [==============================] - 1s 747us/step - loss: 0.0651 - accuracy: 0.9799\n",
      "Epoch 7/500\n",
      "1875/1875 [==============================] - 1s 688us/step - loss: 0.0596 - accuracy: 0.9811\n",
      "Epoch 8/500\n",
      "1875/1875 [==============================] - 1s 699us/step - loss: 0.0520 - accuracy: 0.9829\n",
      "Epoch 9/500\n",
      "1875/1875 [==============================] - 1s 698us/step - loss: 0.0475 - accuracy: 0.9845\n",
      "Epoch 10/500\n",
      "1875/1875 [==============================] - 1s 694us/step - loss: 0.0450 - accuracy: 0.9855\n",
      "Epoch 11/500\n",
      "1875/1875 [==============================] - 1s 728us/step - loss: 0.0405 - accuracy: 0.9862\n",
      "Epoch 12/500\n",
      "1875/1875 [==============================] - 1s 697us/step - loss: 0.0391 - accuracy: 0.9866\n",
      "Epoch 13/500\n",
      "1875/1875 [==============================] - 1s 701us/step - loss: 0.0359 - accuracy: 0.9878\n",
      "Epoch 14/500\n",
      "1875/1875 [==============================] - 1s 718us/step - loss: 0.0343 - accuracy: 0.9885\n",
      "Epoch 15/500\n",
      "1875/1875 [==============================] - 1s 731us/step - loss: 0.0317 - accuracy: 0.9891\n",
      "Epoch 16/500\n",
      "1875/1875 [==============================] - 1s 712us/step - loss: 0.0305 - accuracy: 0.9899\n",
      "Epoch 17/500\n",
      "1875/1875 [==============================] - 1s 725us/step - loss: 0.0279 - accuracy: 0.9904\n",
      "Epoch 18/500\n",
      "1875/1875 [==============================] - 1s 672us/step - loss: 0.0276 - accuracy: 0.9905\n",
      "Epoch 19/500\n",
      "1875/1875 [==============================] - 1s 696us/step - loss: 0.0284 - accuracy: 0.9902\n",
      "Epoch 20/500\n",
      "1875/1875 [==============================] - 1s 701us/step - loss: 0.0264 - accuracy: 0.9909\n",
      "Epoch 21/500\n",
      "1875/1875 [==============================] - 1s 691us/step - loss: 0.0242 - accuracy: 0.9912\n",
      "Epoch 22/500\n",
      "1875/1875 [==============================] - 1s 706us/step - loss: 0.0249 - accuracy: 0.9912\n",
      "Epoch 23/500\n",
      "1875/1875 [==============================] - 1s 767us/step - loss: 0.0230 - accuracy: 0.9922\n",
      "Epoch 24/500\n",
      "1875/1875 [==============================] - 1s 764us/step - loss: 0.0229 - accuracy: 0.9921\n",
      "Epoch 25/500\n",
      "1875/1875 [==============================] - 1s 752us/step - loss: 0.0242 - accuracy: 0.9915\n",
      "Epoch 26/500\n",
      "1875/1875 [==============================] - 1s 747us/step - loss: 0.0214 - accuracy: 0.9924\n",
      "Epoch 27/500\n",
      "1875/1875 [==============================] - 1s 736us/step - loss: 0.0224 - accuracy: 0.9919\n",
      "Epoch 28/500\n",
      "1875/1875 [==============================] - 1s 700us/step - loss: 0.0196 - accuracy: 0.9933\n",
      "Epoch 29/500\n",
      "1875/1875 [==============================] - 1s 727us/step - loss: 0.0226 - accuracy: 0.9924\n",
      "Epoch 30/500\n",
      "1875/1875 [==============================] - 1s 700us/step - loss: 0.0203 - accuracy: 0.9927\n",
      "Epoch 31/500\n",
      "1875/1875 [==============================] - 1s 705us/step - loss: 0.0190 - accuracy: 0.9938\n",
      "Epoch 32/500\n",
      "1875/1875 [==============================] - 1s 699us/step - loss: 0.0196 - accuracy: 0.9931\n",
      "Epoch 33/500\n",
      "1875/1875 [==============================] - 1s 748us/step - loss: 0.0192 - accuracy: 0.9933\n",
      "Epoch 34/500\n",
      "1875/1875 [==============================] - 1s 711us/step - loss: 0.0188 - accuracy: 0.9937\n",
      "Epoch 35/500\n",
      "1875/1875 [==============================] - 1s 721us/step - loss: 0.0182 - accuracy: 0.9934\n",
      "Epoch 36/500\n",
      "1875/1875 [==============================] - 1s 704us/step - loss: 0.0171 - accuracy: 0.9941\n",
      "Epoch 37/500\n",
      "1875/1875 [==============================] - 1s 707us/step - loss: 0.0184 - accuracy: 0.9934\n",
      "Epoch 38/500\n",
      "1875/1875 [==============================] - 1s 729us/step - loss: 0.0174 - accuracy: 0.9937\n",
      "Epoch 39/500\n",
      "1875/1875 [==============================] - 1s 715us/step - loss: 0.0190 - accuracy: 0.9936\n",
      "Epoch 40/500\n",
      "1875/1875 [==============================] - 1s 708us/step - loss: 0.0147 - accuracy: 0.9948\n",
      "Epoch 41/500\n",
      "1875/1875 [==============================] - 1s 728us/step - loss: 0.0165 - accuracy: 0.9943\n",
      "Epoch 42/500\n",
      "1875/1875 [==============================] - 1s 719us/step - loss: 0.0183 - accuracy: 0.9940\n",
      "Epoch 43/500\n",
      "1875/1875 [==============================] - 1s 725us/step - loss: 0.0169 - accuracy: 0.9944\n",
      "Epoch 44/500\n",
      "1875/1875 [==============================] - 1s 701us/step - loss: 0.0161 - accuracy: 0.9945\n",
      "Epoch 45/500\n",
      "1875/1875 [==============================] - 1s 730us/step - loss: 0.0154 - accuracy: 0.9947\n",
      "Epoch 46/500\n",
      "1875/1875 [==============================] - 1s 687us/step - loss: 0.0154 - accuracy: 0.9947\n",
      "Epoch 47/500\n",
      "1875/1875 [==============================] - 1s 710us/step - loss: 0.0161 - accuracy: 0.9946\n",
      "Epoch 48/500\n",
      "1875/1875 [==============================] - 1s 711us/step - loss: 0.0140 - accuracy: 0.9952\n",
      "Epoch 49/500\n",
      "1875/1875 [==============================] - 1s 737us/step - loss: 0.0150 - accuracy: 0.9948\n",
      "Epoch 50/500\n",
      "1875/1875 [==============================] - 1s 726us/step - loss: 0.0142 - accuracy: 0.9951\n",
      "Epoch 51/500\n",
      "1875/1875 [==============================] - 1s 715us/step - loss: 0.0152 - accuracy: 0.9948\n",
      "Epoch 52/500\n",
      "1875/1875 [==============================] - 1s 704us/step - loss: 0.0144 - accuracy: 0.9950\n",
      "Epoch 53/500\n",
      "1875/1875 [==============================] - 1s 699us/step - loss: 0.0150 - accuracy: 0.9950\n",
      "Epoch 54/500\n",
      "1875/1875 [==============================] - 1s 716us/step - loss: 0.0151 - accuracy: 0.9948\n",
      "Epoch 55/500\n",
      "1875/1875 [==============================] - 1s 708us/step - loss: 0.0147 - accuracy: 0.9951\n",
      "Epoch 56/500\n",
      "1875/1875 [==============================] - 1s 688us/step - loss: 0.0151 - accuracy: 0.9949\n",
      "Epoch 57/500\n",
      "1875/1875 [==============================] - 1s 704us/step - loss: 0.0136 - accuracy: 0.9957\n",
      "Epoch 58/500\n",
      "1875/1875 [==============================] - 1s 706us/step - loss: 0.0148 - accuracy: 0.9950\n",
      "Epoch 59/500\n",
      "1875/1875 [==============================] - 1s 717us/step - loss: 0.0142 - accuracy: 0.9953\n",
      "Epoch 60/500\n",
      "1875/1875 [==============================] - 1s 719us/step - loss: 0.0147 - accuracy: 0.9952\n",
      "Epoch 61/500\n",
      "1875/1875 [==============================] - 1s 703us/step - loss: 0.0143 - accuracy: 0.9953\n",
      "Epoch 62/500\n",
      "1875/1875 [==============================] - 1s 699us/step - loss: 0.0149 - accuracy: 0.9951\n",
      "Epoch 63/500\n",
      "1875/1875 [==============================] - 1s 713us/step - loss: 0.0132 - accuracy: 0.9956\n",
      "Epoch 64/500\n",
      "1875/1875 [==============================] - 1s 694us/step - loss: 0.0154 - accuracy: 0.9952\n",
      "Epoch 65/500\n",
      "1875/1875 [==============================] - 1s 719us/step - loss: 0.0147 - accuracy: 0.9950\n",
      "Epoch 66/500\n",
      "1875/1875 [==============================] - 1s 693us/step - loss: 0.0161 - accuracy: 0.9951\n",
      "Epoch 67/500\n",
      "1875/1875 [==============================] - 1s 702us/step - loss: 0.0148 - accuracy: 0.9951\n",
      "Epoch 68/500\n",
      "1875/1875 [==============================] - 1s 697us/step - loss: 0.0124 - accuracy: 0.9959\n",
      "Epoch 69/500\n",
      "1875/1875 [==============================] - 1s 700us/step - loss: 0.0136 - accuracy: 0.9955\n",
      "Epoch 70/500\n",
      "1875/1875 [==============================] - 1s 702us/step - loss: 0.0136 - accuracy: 0.9954\n",
      "Epoch 71/500\n",
      "1875/1875 [==============================] - 1s 676us/step - loss: 0.0136 - accuracy: 0.9957\n",
      "Epoch 72/500\n",
      "1875/1875 [==============================] - 1s 704us/step - loss: 0.0129 - accuracy: 0.9955\n",
      "Epoch 73/500\n",
      "1875/1875 [==============================] - 1s 720us/step - loss: 0.0134 - accuracy: 0.9957\n",
      "Epoch 74/500\n",
      "1875/1875 [==============================] - 1s 695us/step - loss: 0.0143 - accuracy: 0.9957\n",
      "Epoch 75/500\n",
      "1875/1875 [==============================] - 1s 704us/step - loss: 0.0127 - accuracy: 0.9958\n",
      "Epoch 76/500\n",
      "1875/1875 [==============================] - 1s 715us/step - loss: 0.0123 - accuracy: 0.9957\n",
      "Epoch 77/500\n",
      "1875/1875 [==============================] - 1s 727us/step - loss: 0.0112 - accuracy: 0.9962\n",
      "Epoch 78/500\n",
      "1875/1875 [==============================] - 1s 717us/step - loss: 0.0135 - accuracy: 0.9956\n",
      "Epoch 79/500\n",
      "1875/1875 [==============================] - 1s 703us/step - loss: 0.0123 - accuracy: 0.9959\n",
      "Epoch 80/500\n",
      "1875/1875 [==============================] - 1s 719us/step - loss: 0.0137 - accuracy: 0.9956\n",
      "Epoch 81/500\n",
      "1875/1875 [==============================] - 1s 724us/step - loss: 0.0111 - accuracy: 0.9961\n",
      "Epoch 82/500\n",
      "1875/1875 [==============================] - 1s 742us/step - loss: 0.0136 - accuracy: 0.9958\n",
      "Epoch 83/500\n",
      "1875/1875 [==============================] - 1s 724us/step - loss: 0.0117 - accuracy: 0.9964\n",
      "Epoch 84/500\n",
      "1875/1875 [==============================] - 1s 720us/step - loss: 0.0133 - accuracy: 0.9962\n",
      "Epoch 85/500\n",
      "1875/1875 [==============================] - 1s 747us/step - loss: 0.0126 - accuracy: 0.9961\n",
      "Epoch 86/500\n",
      "1875/1875 [==============================] - 1s 748us/step - loss: 0.0122 - accuracy: 0.9960\n",
      "Epoch 87/500\n",
      "1875/1875 [==============================] - 1s 768us/step - loss: 0.0114 - accuracy: 0.9964\n",
      "Epoch 88/500\n",
      "1875/1875 [==============================] - 2s 858us/step - loss: 0.0136 - accuracy: 0.9958\n",
      "Epoch 89/500\n",
      "1875/1875 [==============================] - 1s 793us/step - loss: 0.0127 - accuracy: 0.9958\n",
      "Epoch 90/500\n",
      "1875/1875 [==============================] - 1s 774us/step - loss: 0.0107 - accuracy: 0.9964\n",
      "Epoch 91/500\n",
      "1875/1875 [==============================] - 1s 727us/step - loss: 0.0125 - accuracy: 0.9961\n",
      "Epoch 92/500\n",
      "1875/1875 [==============================] - 1s 691us/step - loss: 0.0118 - accuracy: 0.9961\n",
      "Epoch 93/500\n",
      "1875/1875 [==============================] - 1s 682us/step - loss: 0.0137 - accuracy: 0.9957\n",
      "Epoch 94/500\n",
      "1875/1875 [==============================] - 1s 690us/step - loss: 0.0106 - accuracy: 0.9967\n",
      "Epoch 95/500\n",
      "1875/1875 [==============================] - 1s 700us/step - loss: 0.0130 - accuracy: 0.9960\n",
      "Epoch 96/500\n",
      "1875/1875 [==============================] - 1s 699us/step - loss: 0.0123 - accuracy: 0.9959\n",
      "Epoch 97/500\n",
      "1875/1875 [==============================] - 1s 694us/step - loss: 0.0113 - accuracy: 0.9964\n",
      "Epoch 98/500\n",
      "1875/1875 [==============================] - 1s 698us/step - loss: 0.0123 - accuracy: 0.9958\n",
      "Epoch 99/500\n",
      "1875/1875 [==============================] - 1s 702us/step - loss: 0.0127 - accuracy: 0.9958\n",
      "Epoch 100/500\n",
      "1875/1875 [==============================] - 1s 687us/step - loss: 0.0099 - accuracy: 0.9964\n",
      "Epoch 101/500\n",
      "1875/1875 [==============================] - 1s 687us/step - loss: 0.0114 - accuracy: 0.9961\n",
      "Epoch 102/500\n",
      "1875/1875 [==============================] - 1s 670us/step - loss: 0.0113 - accuracy: 0.9965\n",
      "Epoch 103/500\n",
      "1875/1875 [==============================] - 1s 692us/step - loss: 0.0116 - accuracy: 0.9962\n",
      "Epoch 104/500\n",
      "1875/1875 [==============================] - 1s 696us/step - loss: 0.0109 - accuracy: 0.9967\n",
      "Epoch 105/500\n",
      "1875/1875 [==============================] - 1s 762us/step - loss: 0.0119 - accuracy: 0.9965\n",
      "Epoch 106/500\n",
      "1875/1875 [==============================] - 1s 699us/step - loss: 0.0127 - accuracy: 0.9960\n",
      "Epoch 107/500\n",
      "1875/1875 [==============================] - 1s 673us/step - loss: 0.0099 - accuracy: 0.9969\n",
      "Epoch 108/500\n",
      "1875/1875 [==============================] - 1s 713us/step - loss: 0.0120 - accuracy: 0.9960\n",
      "Epoch 109/500\n",
      "1875/1875 [==============================] - 1s 728us/step - loss: 0.0095 - accuracy: 0.9972\n",
      "Epoch 110/500\n",
      "1875/1875 [==============================] - 1s 716us/step - loss: 0.0105 - accuracy: 0.9967\n",
      "Epoch 111/500\n",
      "1875/1875 [==============================] - 1s 694us/step - loss: 0.0094 - accuracy: 0.9970\n",
      "Epoch 112/500\n",
      "1875/1875 [==============================] - 1s 725us/step - loss: 0.0108 - accuracy: 0.9967\n",
      "Epoch 113/500\n",
      "1875/1875 [==============================] - 1s 688us/step - loss: 0.0108 - accuracy: 0.9962\n",
      "Epoch 114/500\n",
      "1875/1875 [==============================] - 1s 709us/step - loss: 0.0117 - accuracy: 0.9964\n",
      "Epoch 115/500\n",
      "1875/1875 [==============================] - 1s 739us/step - loss: 0.0104 - accuracy: 0.9966\n",
      "Epoch 116/500\n",
      "1875/1875 [==============================] - 1s 744us/step - loss: 0.0110 - accuracy: 0.9965\n",
      "Epoch 117/500\n",
      "1875/1875 [==============================] - 1s 754us/step - loss: 0.0127 - accuracy: 0.9961\n",
      "Epoch 118/500\n",
      "1875/1875 [==============================] - 1s 725us/step - loss: 0.0096 - accuracy: 0.9969\n",
      "Epoch 119/500\n",
      "1875/1875 [==============================] - 1s 757us/step - loss: 0.0114 - accuracy: 0.9964\n",
      "Epoch 120/500\n",
      "1875/1875 [==============================] - 1s 795us/step - loss: 0.0103 - accuracy: 0.9968\n",
      "Epoch 121/500\n",
      "1875/1875 [==============================] - 1s 747us/step - loss: 0.0119 - accuracy: 0.9965\n",
      "Epoch 122/500\n",
      "1875/1875 [==============================] - 1s 771us/step - loss: 0.0103 - accuracy: 0.9966\n",
      "Epoch 123/500\n",
      "1875/1875 [==============================] - 1s 745us/step - loss: 0.0108 - accuracy: 0.9967\n",
      "Epoch 124/500\n",
      "1875/1875 [==============================] - 1s 745us/step - loss: 0.0122 - accuracy: 0.9961\n",
      "Epoch 125/500\n",
      "1875/1875 [==============================] - 1s 783us/step - loss: 0.0094 - accuracy: 0.9967\n",
      "Epoch 126/500\n",
      "1875/1875 [==============================] - 1s 796us/step - loss: 0.0104 - accuracy: 0.9967\n",
      "Epoch 127/500\n",
      "1875/1875 [==============================] - 1s 749us/step - loss: 0.0093 - accuracy: 0.9970\n",
      "Epoch 128/500\n",
      "1875/1875 [==============================] - 1s 772us/step - loss: 0.0104 - accuracy: 0.9969\n",
      "Epoch 129/500\n",
      "1875/1875 [==============================] - 1s 736us/step - loss: 0.0097 - accuracy: 0.9966\n",
      "Epoch 130/500\n",
      "1875/1875 [==============================] - 1s 716us/step - loss: 0.0109 - accuracy: 0.9966\n",
      "Epoch 131/500\n",
      "1875/1875 [==============================] - 1s 758us/step - loss: 0.0105 - accuracy: 0.9968\n",
      "Epoch 132/500\n",
      "1875/1875 [==============================] - 1s 777us/step - loss: 0.0104 - accuracy: 0.9966\n",
      "Epoch 133/500\n",
      "1875/1875 [==============================] - 1s 785us/step - loss: 0.0107 - accuracy: 0.9966\n",
      "Epoch 134/500\n",
      "1875/1875 [==============================] - 2s 811us/step - loss: 0.0118 - accuracy: 0.9967\n",
      "Epoch 135/500\n",
      "1875/1875 [==============================] - 1s 792us/step - loss: 0.0104 - accuracy: 0.9968\n",
      "Epoch 136/500\n",
      "1875/1875 [==============================] - 1s 750us/step - loss: 0.0094 - accuracy: 0.9970\n",
      "Epoch 137/500\n",
      "1875/1875 [==============================] - 1s 716us/step - loss: 0.0092 - accuracy: 0.9971\n",
      "Epoch 138/500\n",
      "1875/1875 [==============================] - 1s 720us/step - loss: 0.0091 - accuracy: 0.9969\n",
      "Epoch 139/500\n",
      "1875/1875 [==============================] - 1s 736us/step - loss: 0.0106 - accuracy: 0.9970\n",
      "Epoch 140/500\n",
      "1875/1875 [==============================] - 1s 716us/step - loss: 0.0100 - accuracy: 0.9969\n",
      "Epoch 141/500\n",
      "1875/1875 [==============================] - 1s 686us/step - loss: 0.0095 - accuracy: 0.9967\n",
      "Epoch 142/500\n",
      "1875/1875 [==============================] - 1s 750us/step - loss: 0.0085 - accuracy: 0.9972\n",
      "Epoch 143/500\n",
      "1875/1875 [==============================] - 1s 731us/step - loss: 0.0096 - accuracy: 0.9969\n",
      "Epoch 144/500\n",
      "1875/1875 [==============================] - 1s 707us/step - loss: 0.0087 - accuracy: 0.9973\n",
      "Epoch 145/500\n",
      "1875/1875 [==============================] - 1s 727us/step - loss: 0.0104 - accuracy: 0.9968\n",
      "Epoch 146/500\n",
      "1875/1875 [==============================] - 1s 744us/step - loss: 0.0096 - accuracy: 0.9967\n",
      "Epoch 147/500\n",
      "1875/1875 [==============================] - 1s 720us/step - loss: 0.0100 - accuracy: 0.9972\n",
      "Epoch 148/500\n",
      "1875/1875 [==============================] - 1s 737us/step - loss: 0.0094 - accuracy: 0.9971\n",
      "Epoch 149/500\n",
      "1875/1875 [==============================] - 1s 715us/step - loss: 0.0105 - accuracy: 0.9971\n",
      "Epoch 150/500\n",
      "1875/1875 [==============================] - 1s 728us/step - loss: 0.0105 - accuracy: 0.9971\n",
      "Epoch 151/500\n",
      "1875/1875 [==============================] - 1s 758us/step - loss: 0.0084 - accuracy: 0.9971\n",
      "Epoch 152/500\n",
      "1875/1875 [==============================] - 1s 713us/step - loss: 0.0094 - accuracy: 0.9972\n",
      "Epoch 153/500\n",
      "1875/1875 [==============================] - 1s 755us/step - loss: 0.0101 - accuracy: 0.9967\n",
      "Epoch 154/500\n",
      "1875/1875 [==============================] - 1s 768us/step - loss: 0.0093 - accuracy: 0.9971\n",
      "Epoch 155/500\n",
      "1875/1875 [==============================] - 1s 784us/step - loss: 0.0113 - accuracy: 0.9966\n",
      "Epoch 156/500\n",
      "1875/1875 [==============================] - 1s 756us/step - loss: 0.0088 - accuracy: 0.9973\n",
      "Epoch 157/500\n",
      "1875/1875 [==============================] - 1s 785us/step - loss: 0.0100 - accuracy: 0.9969\n",
      "Epoch 158/500\n",
      "1875/1875 [==============================] - 2s 811us/step - loss: 0.0101 - accuracy: 0.9973\n",
      "Epoch 159/500\n",
      "1875/1875 [==============================] - 2s 801us/step - loss: 0.0089 - accuracy: 0.9972\n",
      "Epoch 160/500\n",
      "1875/1875 [==============================] - 1s 799us/step - loss: 0.0091 - accuracy: 0.9973\n",
      "Epoch 161/500\n",
      "1875/1875 [==============================] - 1s 784us/step - loss: 0.0103 - accuracy: 0.9969\n",
      "Epoch 162/500\n",
      "1875/1875 [==============================] - 1s 774us/step - loss: 0.0106 - accuracy: 0.9967\n",
      "Epoch 163/500\n",
      "1875/1875 [==============================] - 1s 795us/step - loss: 0.0093 - accuracy: 0.9974\n",
      "Epoch 164/500\n",
      "1875/1875 [==============================] - 1s 704us/step - loss: 0.0101 - accuracy: 0.9968\n",
      "Epoch 165/500\n",
      "1875/1875 [==============================] - 1s 726us/step - loss: 0.0099 - accuracy: 0.9969\n",
      "Epoch 166/500\n",
      "1875/1875 [==============================] - 1s 726us/step - loss: 0.0104 - accuracy: 0.9969\n",
      "Epoch 167/500\n",
      "1875/1875 [==============================] - 1s 720us/step - loss: 0.0097 - accuracy: 0.9969\n",
      "Epoch 168/500\n",
      "1875/1875 [==============================] - 1s 739us/step - loss: 0.0098 - accuracy: 0.9971\n",
      "Epoch 169/500\n",
      "1875/1875 [==============================] - 1s 731us/step - loss: 0.0082 - accuracy: 0.9976\n",
      "Epoch 170/500\n",
      "1749/1875 [==========================>...] - ETA: 0s - loss: 0.0092 - accuracy: 0.9973"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-c6b8d87b1f85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;34m'''训练'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m model.fit(x_train,y_train,\n\u001b[1;32m---> 30\u001b[1;33m           epochs=500,callbacks=[callback])\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;34m'''评估'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3040\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1964\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
    "#np.unique(y_train) #[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "'''将像素值除以255是为了将图像的灰度值范围从0到255转换到0到1之间的范围'''\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "'''模型'''\n",
    "model=Sequential([\n",
    "    Flatten(input_shape=(28,28)), #展平\n",
    "    Dense(128, activation='relu'), #全连接\n",
    "    Dropout(0.2), #防止过拟合\n",
    "    Dense(10, activation='softmax') #输出层，激活函数为softmax，用于输出分类结果\n",
    "])\n",
    "\n",
    "'''编译'''\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "'''回调函数记录训练信息'''\n",
    "log_dir=\"logs/fit/mnist\"\n",
    "callback=tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1\n",
    ")\n",
    "\n",
    "'''训练'''\n",
    "model.fit(x_train,y_train,\n",
    "          epochs=500,callbacks=[callback])\n",
    "\n",
    "'''评估'''\n",
    "model.evaluate(x_test,y_test,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f567eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 12, 12, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 16)          2416      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 120)               30840     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 44,426\n",
      "Trainable params: 44,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Layer,Dense,Conv2D,AvgPool2D,Flatten,MaxPool2D,Dropout,concatenate,Input,Softmax,BatchNormalization,Activation,GlobalAveragePooling2D,ReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(X_train,y_train),(X_test,y_test)=mnist.load_data()\n",
    "\n",
    "X_train4D=X_train.reshape(X_train.shape[0],28,28,1).astype('float32')\n",
    "X_test4D = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "#归一化\n",
    "X_train4D_Normalize = X_train4D / 255 # 归一化\n",
    "X_test4D_Normalize = X_test4D / 255\n",
    "\n",
    "#将类别向量映射为二值类别矩阵,将原有的类别向量转换为独热编码的形式\n",
    "y_trainOnehot=to_categorical(y_train)\n",
    "y_testOnehot = to_categorical(y_test)\n",
    "\n",
    "#建立模型\n",
    "model = Sequential()\n",
    "\n",
    "#一层卷积\n",
    "model.add(Conv2D(filters=6,\n",
    "                          kernel_size=(5,5),\n",
    "                          strides=1,\n",
    "                          input_shape=[28,28,1],\n",
    "                          activation='relu'\n",
    "                ))\n",
    "#池化\n",
    "model.add(AvgPool2D(pool_size=(2,2)))\n",
    "#二层卷积\n",
    "model.add(Conv2D(filters=16,\n",
    "                          kernel_size=(5,5),\n",
    "                          strides=1,\n",
    "                          activation='relu'\n",
    "                ))\n",
    "#池化\n",
    "model.add(AvgPool2D(pool_size=(2,2)))\n",
    "\n",
    "#全连接层\n",
    "#将多维输入一维化，即展平操作。这是从卷积层到全连接层的过渡\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120,activation='relu'))\n",
    "model.add(Dense(84,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132505f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2645 - accuracy: 0.9191 - val_loss: 0.1117 - val_accuracy: 0.9657\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0885 - accuracy: 0.9731 - val_loss: 0.0846 - val_accuracy: 0.9758\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0636 - accuracy: 0.9796 - val_loss: 0.0698 - val_accuracy: 0.9793\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0491 - accuracy: 0.9845 - val_loss: 0.0555 - val_accuracy: 0.9826\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0409 - accuracy: 0.9867 - val_loss: 0.0507 - val_accuracy: 0.9847\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0321 - accuracy: 0.9893 - val_loss: 0.0478 - val_accuracy: 0.9870\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 0.0448 - val_accuracy: 0.9872\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0243 - accuracy: 0.9918 - val_loss: 0.0628 - val_accuracy: 0.9839\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0198 - accuracy: 0.9935 - val_loss: 0.0513 - val_accuracy: 0.9862\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.0464 - val_accuracy: 0.9870\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "history=model.fit(x=X_train4D_Normalize,y=y_trainOnehot,epochs=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f755e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.0406 - accuracy: 0.9882\n",
      "\n",
      "Test accuracy: 0.9882000088691711\n",
      "\n",
      "Test loss: 0.04063167795538902\n"
     ]
    }
   ],
   "source": [
    "'''评估'''\n",
    "test_loss, test_acc = model.evaluate(X_test4D_Normalize,y_testOnehot,verbose=2) #损失值和准确率\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "print('\\nTest loss:', test_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
